---
title: "Traditional Methods 207 Final Project"
author: "Dylan Chou, Tim Yao"
date: "2024-05-30"
output: pdf_document
---

```{r, include=F}
library(astsa)
library(tseries)
library(forecast)
library(aTSA)
library(KFAS)
library(mgcv)
library(bayesforecast)
```

## Two Time Series Plots of Electricity and Weather

```{r}
# par(mfrow=c(2,2))
etth1 = read.csv("./data/ETTh1.csv")
etth2 = read.csv("./data/ETTh2.csv")
ettm1 = read.csv("./data/ETTm1.csv")
tail(etth1)
weather = read.csv("./data/WTH.csv")
aeph = read.csv("./data/AEP_hourly.csv")

# univariate time series
# https://stackoverflow.com/questions/33782218/how-to-create-a-time-series-of-hourly-data
first_hour_etth1 = 24*(as.Date("2016-07-01 00:00:00")-as.Date("2016-1-1 00:00:00"))
etth1.ts.original = ts(data=etth1$OT, start=c(2016, first_hour_etth1), freq=24*365)

etth1.ts = (etth1.ts.original-mean(etth1.ts.original))/sd(etth1.ts.original)

etth2.ts.original = ts(data=etth2$OT, start=c(2016, first_hour_etth1), freq=24*365)
etth2.ts = (etth2.ts.original-mean(etth2.ts.original))/sd(etth2.ts.original)

# ettm1

ettm1.ts.original = ts(data=ettm1$OT, start=c(2016, first_hour_etth1), freq=4*24*365)
ettm1.ts = (ettm1.ts.original-mean(ettm1.ts.original))/sd(ettm1.ts.original)


weather.ts.original = ts(data=weather$WetBulbCelsius, start=c(2010, 0), freq=24*365)
weather.ts = (weather.ts.original-mean(weather.ts.original))/sd(weather.ts.original)


first_hour_aeph = 24*(as.Date("2004-12-31 01:00:00")-as.Date("2004-1-1 00:00:00"))
aeph.ts.original = ts(data=aeph$AEP_MW, start=c(2004, first_hour_aeph), freq=24*365)
aeph.ts = (aeph.ts.original-mean(aeph.ts.original))/sd(aeph.ts.original)

plot(etth1.ts.original, main="ETTH1 Electricity Oil Temperature", ylab="Oil Temperature (Celsius)")
plot(etth2.ts.original, main="ETTH2 Electricity Oil Temperature", ylab="Oil Temperature (Celsius)")
plot(ettm1.ts.original, main="ETTM1 Electricity Oil Temperature", ylab="Oil Temperature (Celsius)")
plot(weather.ts.original, main="Weather Wet Bulb Temperature (Celsius)", ylab="Wet Bulb Temperature (Celsius)")
plot(aeph.ts.original, main="AEPh Megawatt Energy Consumption",ylab="Megawatt Energy Consumption")
```

## Autocorrelation of current time series

```{r}
# original data can't be operated on directly due to slow decrease in acf across lags
par(mfrow=c(2,2))
# first diagnose the autocorrelation of the existing time series

# pacf(etth1.ts, lag.max=200)
acf(etth1.ts, lag.max=200)

acf(etth2.ts, lag.max=200)

acf(ettm1.ts, lag.max=200)

# pacf(weather.ts)
acf(weather.ts, lag.max=200)

acf(aeph.ts, lag.max=2000)
```

```{r}
gen_plots = function(dataset=etth1.ts) {
  par(mfrow=c(2,4))
  etth1_time = time(dataset)
  reg1 = lm(dataset~etth1_time+I(etth1_time^3))
  
  plot(dataset)
  points(etth1_time, predict.lm(reg1),type='l',col='blue')
  
  seasonality_etth1 = dataset-predict.lm(reg1)
  
  f1 = 1
  f2 = 3
  f3 = 12
  d = 24*365
  v1 = cos(2*base::pi*f1*(1:length(dataset))/d)
  v2 = sin(2*base::pi*f1*(1:length(dataset))/d)
  v3 = cos(2*base::pi*f2*(1:length(dataset))/d)
  v4 = sin(2*base::pi*f2*(1:length(dataset))/d)
  v5 = cos(2*base::pi*f3*(1:length(dataset))/d)
  v6 = sin(2*base::pi*f3*(1:length(dataset))/d)
  
  seasonal_fit1 = lm(seasonality_etth1 ~ 1 + v1 + v2 + v3 + v4)
  plot(1:length(dataset), seasonality_etth1, type="l")
  points(1:length(dataset), seasonal_fit1$fitted, type = "l", col = "firebrick",lwd=3)
  
  coef(seasonal_fit1)
  
  after_trend_seasonality_etth1 = seasonality_etth1-seasonal_fit1$fitted
  
  
  gam1 = gam(after_trend_seasonality_etth1 ~ s(time(dataset)))
  
  plot(1:length(dataset), after_trend_seasonality_etth1, type="l")
  points(1:length(dataset), gam1$fitted.values, type = "l", col = "firebrick",lwd=3)
  plot(after_trend_seasonality_etth1-gam1$fitted.values)
  
  
  acf(after_trend_seasonality_etth1-gam1$fitted.values,lag.max=200)
  
}
gen_plots(aeph.ts)

```





## Differencing - trend elimination

```{r}
# etth1
acf(diff(diff(etth1.ts,lag=1), lag=1), lag.max=200)

acf(diff(etth1.ts,lag=24), lag.max=200)
acf(diff(etth1.ts,lag=24*2), lag.max=200)
acf(diff(etth1.ts,lag=4), lag.max=200)

adf.test(etth1.ts)
adf.test(diff(etth1.ts))
stationary.test(etth1.ts)


# etth2
acf(diff(diff(etth2.ts,lag=1), lag=1), lag.max=200)
acf(diff(etth2.ts,lag=24), lag.max=200)
# removes sufficient amount of structure.
acf(diff(diff(diff(etth2.ts,lag=24))), lag.max=200)

adf.test(diff(diff(diff(etth2.ts,lag=1), lag=1), lag=24))
stationary.test(etth2.ts)


# ettm1
acf(diff(diff(ettm1.ts,lag=4*12)), lag.max=200)

acf(diff(ettm1.ts,lag=4), lag.max=200)

acf(diff(diff(diff(ettm1.ts,lag=4))), lag.max=200)

adf.test(ettm1.ts)
stationary.test(ettm1.ts)

# Weather 
acf(diff(diff(weather.ts),lag=1),lag.max=200)

adf.test(weather.ts)
stationary.test(weather.ts)

# Aeph

acf(diff(aeph.ts,lag=24), lag.max=200)

adf.test(aeph.ts)
stationary.test(aeph.ts)
```

## Trying different models based on preliminary plots

```{r}
# ETTH1
# Ideal to difference twice to remove trend. Estimates using CSS-ML
grid_search_cv = function(dataset, ar_range, ma_range, diff_range, periods, seasonal_ma_range, 
                          seasonal_ar_range, pred_lens, n_folds, non_oos_prop,
                          first_year, first_val, dataset_freq) {
  if (n_folds <= 1) {
    stop("Not enough folds")
  }
  
  # OUTPUT
  results = list()
  
  non_oos_size = length(dataset)*non_oos_prop
  non_oos = ts(dataset[1:non_oos_size], start=c(first_year, first_val), freq=dataset_freq)
  chunk_length = as.integer(non_oos_size/n_folds)
  
  for (pred_len in pred_lens) {
    print(paste("Outer Loop prediction length:", pred_len))
    for (fold in 1:(n_folds-1)) {
      train_start = chunk_length*(fold-1)+1
      train_end = fold*chunk_length-1
      
      validation_start = train_end + 1
      if (fold == (n_folds-1)) {
        validation_end = non_oos_size
      } else {
        validation_end = (fold+1)*chunk_length-1
      }
      train = non_oos[train_start:train_end]
      validation = non_oos[validation_start:validation_end]
      for (ar_comp in ar_range) {
        for (ma_comp in ma_range) {
          for (diff in diff_range) {
            print(paste("Current components: ", ar_comp, ",", diff, ",", ma_comp, " - fold: ", fold, sep=""))
            for (curr_period in periods) {
              for (seasonal_ma in seasonal_ma_range) {
                for (seasonal_ar in seasonal_ar_range) {
                  result <- tryCatch({
                    temp_model = arima(train, order = c(ar_comp,diff,ma_comp),
                                     seasonal=list(order=c(seasonal_ar,1,seasonal_ma), 
                                                   period=curr_period))
                      list(success = TRUE, temp_model = temp_model)
                    }, error = function(e) {
                      message("ARIMA(", paste(ar_comp,diff,ma_comp, collapse = ","), ") failed: ", e$message)
                      list(success = FALSE, temp_model = NULL)
                    })
                  if (!result$success) {
                    next
                  }
                  
                  pred_call = predict(temp_model, n.ahead=pred_len)
                  curr_pred = pred_call$pred
                  mse = mean( (validation[1:pred_len]-curr_pred)^2 )
                  mae = mean( abs(validation[1:pred_len]-curr_pred) )
                  
                  results[[paste("(",ar_comp,",",diff,",",ma_comp, ",",seasonal_ar,",1,",
                                 seasonal_ma,", curr_period:", 
                                 curr_period,", prediction length:" ,
                                 pred_len, " MSE", sep="")]] =
                    c(results[[paste("(",ar_comp,",",diff,",",ma_comp, ",",seasonal_ar,",1,",
                                 seasonal_ma,", curr_period:", 
                                 curr_period,", prediction length:" ,
                                 pred_len, " MSE", sep="")]], mse)
                  results[[paste("(",ar_comp,",",diff,",",ma_comp, ",",seasonal_ar,",1,",
                                 seasonal_ma,", curr_period:", 
                                 curr_period,", prediction length:" ,
                                 pred_len, " MAE", sep="")]] =
                    c(results[[paste("(",ar_comp,",",diff,",",ma_comp, ",",seasonal_ar,",1,",
                                 seasonal_ma,", curr_period:", 
                                 curr_period,", prediction length:" ,
                                 pred_len, " MAE", sep="")]], mae)
                }
              }
            }
          }
        }
      }
    }
  }
  return(results)
}

# limit prediction lengths to long term (2nd longest).
etth1_gridsearch = grid_search_cv(etth1.ts, 0:2, 0:2, 1, periods=24, seasonal_ma_range=0:1,  
               seasonal_ar_range=0:0, pred_lens=c(336), n_folds=4, 
               non_oos_prop=0.8, first_year = 2016, first_val = first_hour_etth1, 
               dataset_freq = 24*365)

lapply(etth1_gridsearch, mean)

etth2_gridsearch = grid_search_cv(etth2.ts, 0:2, 0:2, 1:2, periods=24, seasonal_ma_range=0:1,  
               seasonal_ar_range=0:0, pred_lens=c(336), n_folds=4, 
               non_oos_prop=0.8, first_year = 2016, first_val = first_hour_etth1, 
               dataset_freq = 24*365)

lapply(etth2_gridsearch, mean)


# diff restricted to 0 -> 2 appears to flare up autocorrelations at lower lags.
ettm1_gridsearch = grid_search_cv(ettm1.ts, 0:2, 0:2, 0, periods=c(4,4*12), seasonal_ma_range=0:1,
               seasonal_ar_range=0:1, pred_lens=c(288), n_folds=4, 
               non_oos_prop=0.8, first_year = 2016, first_val = 4368, 
               dataset_freq = 24*365*4)

lapply(ettm1_gridsearch, mean)


# seasonal component every 24 time steps (every 24 hours).
ettm1_model2 = arima(ettm1.ts, order = c(0,1,1), seasonal=list(order=c(0,1,0), period=4))

plot(ettm1.ts)
ettm1_fit2 = ettm1.ts - residuals(ettm1_model2)
points(ettm1_fit2, type = "l", col = "firebrick", lty = 2, lwd=0.2)

acf(residuals(ettm1_model2), lag.max=200)

# significant lag 1 and 2 components. Trying MA component
# seasonal ma are along the edge of unit circle
ettm1_model3 = arima(ettm1.ts, order = c(1,0,1), seasonal=list(order=c(0,1,1), period=4*12))
plot(ettm1.ts)
ettm1_fit3 = ettm1.ts - residuals(ettm1_model3)
points(ettm1_fit3, type = "l", col = "lightgreen", lty = 2, lwd=0.2)

acf(residuals(ettm1_model3), lag.max=300)


weather_model3 = arima(weather.ts, order = c(0,1,1), seasonal=list(order=c(0,1,0), period=24))
plot(weather.ts)
weather_fit3 = weather.ts - residuals(weather_model3)
points(weather_fit3, type = "l", col = "lightgreen", lty = 2, lwd=0.2)

acf(residuals(weather_model3), lag.max=300)


aeph_model3 = arima(aeph.ts, order = c(1,1,1), seasonal=list(order=c(0,1,0), period=24))
plot(aeph.ts)
aeph_fit3 = aeph.ts - residuals(aeph_model3)
points(aeph_fit3, type = "l", col = "lightgreen", lty = 2, lwd=0.2)

acf(residuals(aeph_model3), lag.max=300)


```


```{r}

# ETTh1: order = c(1,1,2), seasonal=list(order=c(0,1,1), period=24)
# ETTh2: order = c(2,1,1), seasonal=list(order=c(0,1,1), period=24)


# Evaluation
# Coefficients from SARIMA may be close to extremes of the unit circle.
# Train/Validation/Test Split
get_evaluation_on_ts = function(input_ts=etth1.ts, original_input_ts=etth1.ts.original,include_trend_seasonality=F) {
  # get validation middle 0.2 next time
  train_prop = 0.8
  test_prop = 0.2
  train_size = (train_prop*length(input_ts))
  train = ts(input_ts[1:train_size], start=c(2016, first_hour_etth1), freq=24*365*4)
  # train = ts(input_ts[1:train_size], start=c(2004, first_hour_aeph), freq=24*365)
  test_start = train_size+1
  # test = ts(input_ts[test_start:length(input_ts)], start=c(2017,25071), freq=24*365*4)
  # test = ts(input_ts[test_start:length(input_ts)], start=c(2013,1770), freq=24*365)
  test = ts(input_ts[test_start:length(input_ts)])#, start=c(2016,658), freq=24*365)
  # evaluated_model1 = arima(train, order = c(1,2,2), seasonal=list(order=c(0,1,1), period=24))
  # evaluated_model1 = arima(train, order = c(0,1,2), seasonal=list(order=c(0,1,2), period=24))
  if (include_trend_seasonality) {
    time_var_train = time(train)
    reg1_ = lm(train~time_var_train+I(time_var_train^3))
    seasonality_data = train-predict.lm(reg1_)
    
    f1 = 1
    f2 = 12
    d = 24*365
    v1 = cos(2*base::pi*f1*(1:train_size)/d)
    v2 = sin(2*base::pi*f1*(1:train_size)/d)
    v3 = cos(2*base::pi*f2*(1:train_size)/d)
    v4 = sin(2*base::pi*f2*(1:train_size)/d)
    seasonal_fit_ = lm(seasonality_data ~ 1 + v1 + v2 + v3 + v4)

    processed_train = seasonality_data-seasonal_fit_$fitted
    
    # evaluated_model1 = arima(processed_train, order = c(1,1,2), seasonal=list(order=c(0,1,1), period=24))
    # evaluated_model1 = arima(processed_train, order = c(0,1,1), seasonal=list(order=c(0,1,1), period=24))
    # evaluated_model1 = arima(processed_train, order = c(2,1,1), seasonal=list(order=c(0,1,1), period=24))
    evaluated_model1 = arima(processed_train, order=c(1,1,2), seasonal=list(order=c(1,1,1), period=4*12) )
    # evaluated_model1 = arima(processed_train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24*2))
    # evaluated_model1 = arima(processed_train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24))
  } else {
    # evaluated_model1 = arima(train, order = c(2,1,1), seasonal=list(order=c(0,1,1), period=24))
    # evaluated_model1 = arima(train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24*2))
    # evaluated_model1 = arima(train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24))
    # evaluated_model1 = arima(train, order = c(1,1,2), seasonal=list(order=c(0,1,1), period=24))
    evaluated_model1 = arima(train, order=c(1,1,2), seasonal=list(order=c(1,1,1), period=4*12) )
  }
  
  
  # may add as a parameter
  res_lst = list()
  for (pred_len in c(24, 48, 96, 288, 672)) {
    pred_call = predict(evaluated_model1, n.ahead=pred_len)
    curr_pred = pred_call$pred
    if (include_trend_seasonality) {
      reg1_preds = coef(reg1_)[[1]] + coef(reg1_)[[2]]*time(test)[1:pred_len] + coef(reg1_)[[3]]*(time(test)[1:pred_len]^3)

      v1 = cos(2*base::pi*f1*(test_start:(test_start+pred_len-1))/d)
      v2 = sin(2*base::pi*f1*(test_start:(test_start+pred_len-1))/d)
      v3 = cos(2*base::pi*f2*(test_start:(test_start+pred_len-1))/d)
      v4 = sin(2*base::pi*f2*(test_start:(test_start+pred_len-1))/d)
      seasonal_preds = coef(seasonal_fit_)[[1]]+coef(seasonal_fit_)[[2]]*v1+
                       coef(seasonal_fit_)[[3]]*v2+coef(seasonal_fit_)[[4]]*v3+
                       coef(seasonal_fit_)[[5]]*v4
      curr_pred = curr_pred + reg1_preds+seasonal_preds
    }
    curr_se = pred_call$se
    plot(1:pred_len, test[1:pred_len]*sd(original_input_ts)+mean(original_input_ts),type="l",xlab="Time Steps", ylab="Megawatt Energy Consumption")
    points(1:pred_len, curr_pred*sd(original_input_ts)+mean(original_input_ts),type="l",col="darkblue")
  }
  return()
}

# get_evaluation_on_ts(etth1.ts,original_input_ts=etth1.ts.original,include_trend_seasonality=F)
# get_evaluation_on_ts(etth2.ts,original_input_ts=etth2.ts.original, include_trend_seasonality=F)
get_evaluation_on_ts(ettm1.ts,original_input_ts=ettm1.ts.original, include_trend_seasonality=F)
# get_evaluation_on_ts(weather.ts,original_input_ts=weather.ts.original, include_trend_seasonality=F)
# get_evaluation_on_ts(aeph.ts,original_input_ts=aeph.ts.original, include_trend_seasonality=T)

```

```{r}
get_evaluation_on_ts = function(input_ts=etth1.ts, include_trend_seasonality=F) {
  train_prop = 0.8
  test_prop = 0.2
  train_size = (train_prop*length(input_ts))
  test_size = (test_prop*length(input_ts))
  res_lst = list()
  for (pred_len in c(24, 48, 96, 288, 672)) {
    avg_mse = 0
    avg_mae = 0
    for (trial in 1:10){
      print(paste("Prediction Length:", pred_len, "Trial:", trial))
      offset = sample(0:(test_size-pred_len), size=1)
      # train = ts(input_ts[(1+offset):(train_size+offset)], start=c(2010, offset), freq=24*365)
      train = ts(input_ts[1:train_size], start=c(2004, first_hour_aeph), freq=24*365)
      
      test_start = train_size+1
      # 2018, 784 for hourly etth
      # test = ts(input_ts[test_start:length(input_ts)], start=c(2013,1770), freq=24*365)
      test = ts(input_ts[test_start:length(input_ts)], start=c(2016,658), freq=24*365)
      if (include_trend_seasonality) {
        time_var_train = time(train)
        reg1_ = lm(train~time_var_train+I(time_var_train^3))
        seasonality_data = train-predict.lm(reg1_)
        
        f1 = 1
        f2 = 12
        d = 24*365
        v1 = cos(2*base::pi*f1*((1+offset):(train_size+offset) )/d)
        v2 = sin(2*base::pi*f1*((1+offset):(train_size+offset) )/d)
        v3 = cos(2*base::pi*f2*((1+offset):(train_size+offset) )/d)
        v4 = sin(2*base::pi*f2*((1+offset):(train_size+offset) )/d)
        seasonal_fit_ = lm(seasonality_data ~ 1 + v1 + v2 + v3 + v4)
    
        processed_train = seasonality_data-seasonal_fit_$fitted
        evaluated_model1 = arima(processed_train, order = c(1,1,2), seasonal=list(order=c(0,1,1), period=24))
        # evaluated_model1 = arima(processed_train, order = c(0,1,1), seasonal=list(order=c(0,1,1), period=24))
        # evaluated_model1 = arima(processed_train, order = c(0,0,1), seasonal=list(order=c(0,1,0), period=4*12))
        # evaluated_model1 = arima(processed_train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24*2))
        # evaluated_model1 = arima(processed_train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24))
      } else {
        evaluated_model1 = arima(train, order = c(1,1,2), seasonal=list(order=c(0,1,1), period=24))
        # evaluated_model1 = arima(train, order = c(1,2,2), seasonal=list(order=c(0,1,1), period=24))
        # evaluated_model1 = arima(train, order = c(0,0,1), seasonal=list(order=c(0,1,0), period=4*12))
        # evaluated_model1 = arima(train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24*2))
        # evaluated_model1 = arima(train, order = c(1,0,1), seasonal=list(order=c(0,1,0), period=24))
      }
      pred_call = predict(evaluated_model1, n.ahead=pred_len)
      curr_pred = pred_call$pred
      if (include_trend_seasonality) {
        reg1_preds = coef(reg1_)[[1]] + coef(reg1_)[[2]]*time(test)[(1+offset):(offset+pred_len)] + coef(reg1_)[[3]]*(time(test)[(1+offset):(offset+pred_len)]^3)
  
        v1 = cos(2*base::pi*f1*((test_start+offset):(test_start+offset+pred_len-1))/d)
        v2 = sin(2*base::pi*f1*((test_start+offset):(test_start+offset+pred_len-1))/d)
        v3 = cos(2*base::pi*f2*((test_start+offset):(test_start+offset+pred_len-1))/d)
        v4 = sin(2*base::pi*f2*((test_start+offset):(test_start+offset+pred_len-1))/d)
        seasonal_preds = coef(seasonal_fit_)[[1]]+coef(seasonal_fit_)[[2]]*v1+
                         coef(seasonal_fit_)[[3]]*v2+coef(seasonal_fit_)[[4]]*v3+
                         coef(seasonal_fit_)[[5]]*v4
        curr_pred = curr_pred + reg1_preds+seasonal_preds
      }
      curr_se = pred_call$se
      mse = mean( (test[(1+offset):(pred_len+offset)]-curr_pred)^2)
      mae = mean( abs(test[(1+offset):(pred_len+offset)]-curr_pred))
      avg_mse = avg_mse + mse
      avg_mae = avg_mae + mae
    }
    res_lst[paste("mse_",pred_len,sep="")] = avg_mse/10
    res_lst[paste("mae_",pred_len,sep="")] = avg_mae/10
  }
  return(res_lst)
}

# get_evaluation_on_ts(etth2.ts,include_trend_seasonality=T)
get_evaluation_on_ts(etth1.ts,include_trend_seasonality=F)
# get_evaluation_on_ts(ettm1.ts,include_trend_seasonality=T)
# get_evaluation_on_ts(weather.ts,include_trend_seasonality=F)
# get_evaluation_on_ts(aeph.ts,include_trend_seasonality=F)

```





